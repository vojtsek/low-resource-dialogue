\chapter*{List of Publications}

\phantom{\nobibliography*{references}}
\noindent We first present list of publications in which the author of this thesis is the main author, followed with more publications to which the author contributed. The number of citations was computed using Google Scholar.

Total number of citations: 112 


\vfill

% -----------------------------------------------------------------------------
\noindent\bibentry{hudecek-etal-2021-discovering}
\begin{itemize}[noitemsep,topsep=0pt]

\item This work presents pipeline method for unsupervised slot discovery.
\item Citations: 20

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{hudecek-dusek-2023-large}
\begin{itemize}[noitemsep,topsep=0pt]

\item In this work we use large language models and in-context learning to model task-oriented dialogue.

\item Citations: 8
\end{itemize}\vspace{.5\baselineskip}


% -----------------------------------------------------------------------------
\noindent\bibentry{hudecek-dusek-2022-learning}
\begin{itemize}[noitemsep,topsep=0pt]

\item In this publication we introduce our dialogue model with variational training and discrete latent space.
\item Citations: 1

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{hudecek-etal-2022-unifying}
\begin{itemize}[noitemsep,topsep=0pt]

\item In this work we present novel dialogue corpus and related experiments.
\item Citations: 0

\end{itemize}\vspace{.5\baselineskip}


% -----------------------------------------------------------------------------
\noindent\bibentry{kulhanek-etal-2021-augpt}
\begin{itemize}[noitemsep,topsep=0pt]

\item This work presents the AuGPT model and related experiments. It also describes the DSTC 8 challenge participation.
\item Citations: 44

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{straka-etal-2018-sumeczech}
\begin{itemize}[noitemsep,topsep=0pt]

\item This publication describes a dataset that can be used for training of summarization models of news in Czech language and related experiments.
\item Citations: 22

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{platek2016recurrent}
\begin{itemize}[noitemsep,topsep=0pt]

\item In this publication we introduce an RNN-based model used to dialogue state tracking as a sequence modeling task.

\item Citations: 11

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{schaub-etal-2021-definition}
\begin{itemize}[noitemsep,topsep=0pt]

\item This work discusses the inconsistencies and problems found in dialogue corpora
\item Citations: 5

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{mukherjee2023polite}
\begin{itemize}[noitemsep,topsep=0pt]

\item In this work we explore the abilities of language models for text style transfer.
\item Citations: 1

\end{itemize}\vspace{.5\baselineskip}

% -----------------------------------------------------------------------------
\noindent\bibentry{platek2023three}
\begin{itemize}[noitemsep,topsep=0pt]

\item In this work we propose ways of evaluating dialogue qualities with large language models and describe our submission to the DSTC 11 challenge.
\item Citations: 0

\end{itemize}\vspace{.5\baselineskip}