This thesis focuses on developing and improving task-oriented dialogue systems (DS) design in the rapidly growing landscape of artificial intelligence and natural language processing.
We propose techniques that can substantially decrease development and deployment costs, motivated by the desire to make these systems more adaptable and scalable.

We introduce multiple approaches to achieving these goals, some of which we are pioneering.
Firstly, we present a weakly supervised automatic data annotation pipeline that can transform raw data into a refined set of semantically coherent concepts, bypassing the need for exhaustive manual annotations and significantly streamlining the process.
We also explore the largely uninvestigated field of latent variable models in task-oriented dialogue system modeling.
These models offer great capabilities with the potential to uncover the structure of behavioral patterns seen in the dialogue through inspection of the latent space and comparison with actions taken by the model.
Moreover, we harness the power of large pre-trained language models, following the progress in natural language processing.
This leads to high performances with a fraction of the usual training data, implying a substantial leap in efficiently using computational resources to train conversational AI.
This brings us closer to more flexible and general-purpose systems.

In summary, the research presented in this thesis brings exciting innovations, uncovering new pathways in developing task-oriented dialogue systems.
It moves towards a future where dialogue systems can adapt, learn, and interact efficiently, potentially transforming how we interact with technology.
