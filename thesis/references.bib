% Add your custom references in this file

@article{bahdanau2014neural,
  author =	 {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  title =	 {Neural Machine Translation by Jointly Learning to Align and
                  Translate},
  journal =	 {CoRR},
  issn =	 {2331-8422},
  volume =	 {abs/1409.0473},
  year =	 2014
}

@inproceedings{vaswani2017attention,
  author =	 {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and
                  Kaiser, {\L}ukasz and Polosukhin, Illia},
  title =	 {Attention is All You Need},
  booktitle =	 {Advances in Neural Information Processing Systems 30},
  address =	 {Long Beach, CA, USA},
  month =	 {December},
  pages =	 {6000--6010},
  publisher =	 {Curran Associates, Inc.},
  year =	 2017
}

@inproceedings{random,
    title = "Paper title",
    author = "Random Author and Random Co-author",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    pages = "1780--1790"
}


@inproceedings{williams2013dialog,
  title={The dialog state tracking challenge},
  author={Williams, Jason and Raux, Antoine and Ramachandran, Deepak and Black, Alan},
  booktitle={Proceedings of SIGDIAL},
  pages={404--413},
  url={https://www.aclweb.org/anthology/W13-4065/},
  year={2013}
}
@inproceedings{mrkvsic2016neural,
  title={Neural belief tracker: Data-driven dialogue state tracking},
  author={Mrk{\v{s}}i{\'c}, Nikola and S{\'e}aghdha, Diarmuid O and Wen, Tsung-Hsien and Thomson, Blaise and Young, Steve},
  booktitle={Proceedings of ACL},
  url={https://www.aclweb.org/anthology/P17-1163},
  pages={1777--1788},
  year={2017}
}
@inproceedings{tur2012exploiting,
  title={Exploiting the semantic web for unsupervised natural language semantic parsing},
  author={Tur, Gokhan and Jeong, Minwoo and Wang, Ye-Yi and Hakkani-T{\"u}r, Dilek and Heck, Larry},
  booktitle={13th Annual Conference of the International Speech Communication Association},
  year={2012}
}
@inproceedings{heck2012exploiting,
  title={Exploiting the semantic web for unsupervised spoken language understanding},
  author={Heck, Larry and Hakkani-T{\"u}r, Dilek},
  booktitle={Proceedings of IEEE SLT},
  pages={228--233},
  year={2012},
  doi={10.1109/SLT.2012.6424227},
  XXXorganization={IEEE}
}

@inproceedings{hakkani2013using,
  title={Using a knowledge graph and query click logs for unsupervised learning of relation detection},
  author={Hakkani-T{\"u}r, Dilek and Heck, Larry and Tur, Gokhan},
  booktitle={Proceedings of IEEE ICASSP},
  pages={8327--8331},
  year={2013},
  doi={10.1109/ICASSP.2013.6639289},
  XXXorganization={IEEE}
}
@inproceedings{wang2014leveraging,
  title={Leveraging semantic web search and browse sessions for multi-turn spoken dialog systems},
  author={Wang, Lu and Heck, Larry and Hakkani-T{\"u}r, Dilek},
  booktitle={Proceedings of IEEE ICASSP},
  pages={4082--4086},
  year={2014},
  doi={10.1109/ICASSP.2014.6854369},
  XXXorganization={IEEE}
}
@inproceedings{chen2014leveraging,
  title={Leveraging frame semantics and distributional semantics for unsupervised semantic slot induction in spoken dialogue systems},
  author={Chen, Yun-Nung and Wang, William Yang and Rudnicky, Alexander I},
  booktitle={Proceedings of IEEE SLT},
  pages={584--589},
  year={2014},
  XXXorganization={IEEE},
  doi={10.1109/SLT.2014.7078639},
}

@article{fillmore1976frame,
  title={Frame semantics and the nature of language},
  author={Fillmore, Charles J},
  journal={Annals of the New York Academy of Sciences},
  year={1976},
  pages={20--32},
  volume={280},
  number={1},
  url={https://doi.org/10.1111/j.1749-6632.1976.tb25467.x},
  XXXpublisher={Wiley Online Library}
}
@inproceedings{baker1998berkeley,
  title={The berkeley framenet project},
  author={Baker, Collin F and Fillmore, Charles J and Lowe, John B},
  booktitle={Proceedings of COLING},
  pages={86--90},
  year={1998},
  XXXorganization={ACL}
}
@inproceedings{das2010semafor,
	address = {Los Angeles, California},
	title = {Probabilistic Frame-semantic Parsing},
	url = {https://www.aclweb.org/anthology/N10-1138},
	booktitle = {Proceedings of NAACL-HLT},
	author = {Das, Dipanjan and Schneider, Nathan and Chen, Desai and Smith, Noah A.},
	XXXmonth = jun,
	year = {2010},
	pages = {948--956},
}
@article{swayamdipta2017frame,
  title={Frame-semantic parsing with softmax-margin segmental {RNN}s and a syntactic scaffold},
  author={Swayamdipta, Swabha and Thomson, Sam and Dyer, Chris and Smith, Noah A},
  journal={arXiv:1706.09528},
  url={https://arxiv.org/abs/1706.09528},
  year={2017}
}
@article{harris1954distributional,
  title={Distributional structure},
  author={Harris, Zellig S},
  journal={Word},
  volume={10},
  number={2-3},
  pages={146--162},
  year={1954},
  publisher={Taylor \& Francis}
}
@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Proceedings of NeurIPS},
  pages={3111--3119},
  year={2013}
}
@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle={Proceedings of EMNLP},
  pages={1532--1543},
  year={2014}
}
@inproceedings{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  booktitle={Proceedings of NAACL},
  address = {New Orleans, LA, USA},
  year={2018}
}
@inproceedings{sun2014generalized,
  title={A generalized rule based tracker for dialogue state tracking},
  author={Sun, Kai and Chen, Lu and Zhu, Su and Yu, Kai},
  booktitle={Proceedings of IEEE SLT},
  pages={330--335},
  year={2014},
  XXXorganization={IEEE}
}
@inproceedings{zilka2013comparison,
  title={Comparison of bayesian discriminative and generative models for dialogue state tracking},
  author={Zilka, Lukas and Marek, David and Korvas, Matej and Jurcicek, Filip},
  booktitle={Proceedings of the SIGDIAL 2013 Conference},
  pages={452--456},
  year={2013}
}
@article{traum1992conversation,
  title={Conversation acts in task-oriented spoken dialogue},
  author={Traum, David R and Hinkelman, Elizabeth A},
  journal={Computational intelligence},
  volume={8},
  number={3},
  pages={575--599},
  year={1992},
  XXXpublisher={Wiley Online Library}
}

@inproceedings{wen2016network,
  title={A network-based end-to-end trainable task-oriented dialogue system},
  author={Wen, Tsung-Hsien and Vandyke, David and Mrksić, Nikola and Gašić, Milica and Rojas-Barahona, Lina M and Su, Pei-Hao and Ultes, Stefan and Young, Steve},
  booktitle={Proceedings of EACL},
  year={2017},
  XXXaddress={Valencia, Spain},
  url={https://www.aclweb.org/anthology/E17-1042},
  pages={438--449},
}
@inproceedings{liu2017end,
  title={End-to-end optimization of task-oriented dialogue model with deep reinforcement learning},
  author={Liu, Bing and Tur, Gokhan and Hakkani-Tur, Dilek and Shah, Pararth and Heck, Larry},
  booktitle={Proceedings of NeurIPS ConvAI},
  year={2017}
}
@inproceedings{liubing2017end,
  title={An end-to-end trainable neural network model with belief tracking for task-oriented dialog},
  author={Liu, Bing and Lane, Ian},
  booktitle={Proceedings of Interspeech},
  year={2017},
  address={Stockholm, Sweden},
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={JMLR},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}
@article{deerwester1990indexing,
  title={Indexing by latent semantic analysis},
  author={Deerwester, Scott and Dumais, Susan T and Furnas, George W and Landauer, Thomas K and Harshman, Richard},
  journal={Journal of the American society for information science},
  volume={41},
  number={6},
  pages={391--407},
  year={1990},
  XXXpublisher={Wiley Online Library}
}
@inproceedings{hofmann2017probabilistic,
  title={Probabilistic latent semantic indexing},
  author={Hofmann, Thomas},
  booktitle={ACM SIGIR Forum},
  volume={51},
  number={2},
  pages={211--218},
  year={2017},
  XXXorganization={ACM}
}
@inproceedings{yan2013biterm,
  title={A biterm topic model for short texts},
  author={Yan, Xiaohui and Guo, Jiafeng and Lan, Yanyan and Cheng, Xueqi},
  booktitle={Proceedings of WWW},
  pages={1445--1456},
  year={2013},
  XXXorganization={ACM}
}
@inproceedings{klementiev2007unsupervised,
  title={An unsupervised learning algorithm for rank aggregation},
  author={Klementiev, Alexandre and Roth, Dan and Small, Kevin},
  booktitle={Proceedings of ECML},
  pages={616--623},
  year={2007},
  XXXorganization={Springer}
}
@inproceedings{jin2018explicit,
  title={Explicit State Tracking with Semi-Supervision for Neural Dialogue Generation},
  author={Jin, Xisen and Lei, Wenqiang and Ren, Zhaochun and Chen, Hongshen and Liang, Shangsong and Zhao, Yihong and Yin, Dawei},
  booktitle={Proceedings of ACM CIKM},
  pages={1403--1412},
  year={2018},
  doi={10.1145/3269206.3271683},
  XXXorganization={ACM}
}
@article{hinton2006reducing,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  XXXpublisher={American Association for the Advancement of Science}
}
@inproceedings{ng2002spectral,
  title={On spectral clustering: Analysis and an algorithm},
  author={Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
  booktitle={Proceedings of NeurIPS},
  pages={849--856},
  year={2002}
}
@inproceedings{budzianowski2018multiwoz,
  title={{MultiWOZ} -- a large-scale multi-domain {Wizard-of-Oz} dataset for task-oriented dialogue modelling},
  author={Budzianowski, Pawe{\l} and Wen, Tsung-Hsien and Tseng, Bo-Hsiang and Casanueva, Inigo and Ultes, Stefan and Ramadan, Osman and Ga{\v{s}}i{\'c}, Milica},
  booktitle={Proceedings of EMNLP},
  url={https://www.aclweb.org/anthology/D18-1547},
  year={2018}
}
@article{kelley1984iterative,
  title={An iterative design methodology for user-friendly natural language office information applications},
  author={Kelley, John F},
  journal={ACM Transactions on Information Systems},
  volume={2},
  number={1},
  pages={26--41},
  year={1984},
  XXXpublisher={ACM}
}
@article{mikolov2010recurrent,
  title={Recurrent neural network based language model},
  author={Mikolov, Tom{\'a}{\v{s}} and Karafi{\'a}t, Martin and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  journal={Interspeech 2010},
  year={2010},
  publisher={ISCA}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
journal={},
  publisher={OpenAI}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{dong2022survey,
  title={A survey for in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{min2022rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@inproceedings{tu-etal-2022-prompt,
    title = "Prompt-Tuning Can Be Much Better Than Fine-Tuning on Cross-lingual Understanding With Multilingual Language Models",
    author = "Tu, Lifu  and
      Xiong, Caiming  and
      Zhou, Yingbo",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.401",
    pages = "5478--5485",
    abstract = "Pre-trained multilingual language models show significant performance gains for zero-shot cross-lingual model transfer on a wide range of natural language understanding (NLU) tasks. Previously, for zero-shot cross-lingual evaluation, pre-trained models are only fine-tuned on English data and tested on a variety of target languages. In this paper, we do cross-lingualevaluation on various NLU tasks (sentence classification, sequence labeling, question answering) using prompt-tuning and compare it with fine-tuning. The results show that prompt tuning achieves much better cross-lingual transfer than fine-tuning across datasets, with only 0.1{\%} to 0.3{\%} tuned parameters. Additionally, we demonstrate through the analysis that prompt tuning can have better cross-lingual transfer-ability of representations on downstream tasks with better aligned decision boundaries.",
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{pfeiffer2020AdapterHub,
    title={AdapterHub: A Framework for Adapting Transformers},
    author={Pfeiffer, Jonas and
            R{\"u}ckl{\'e}, Andreas and
            Poth, Clifton and
            Kamath, Aishwarya and
            Vuli{\'c}, Ivan and
            Ruder, Sebastian and
            Cho, Kyunghyun and
            Gurevych, Iryna},
    booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
    pages={46--54},
    year={2020}
}


@inproceedings{manning2014stanford,
  title={The Stanford CoreNLP natural language processing toolkit},
  author={Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
  booktitle={Proceedings of ACL},
  pages={55--60},
  year={2014}
}
@inproceedings{pereira1993distributional,
  title={Distributional clustering of English words},
  author={Pereira, Fernando and Tishby, Naftali and Lee, Lillian},
  booktitle={Proceedings of ACL},
  pages={183--190},
  year={1993},
  XXXorganization={Association for Computational Linguistics}
}
@inproceedings{kneser1993improved,
  title={Improved clustering techniques for class-based statistical language modelling},
  author={Kneser, Reinhard and Ney, Hermann},
  booktitle={3rd European Conference on Speech Communication and Technology},
  year={1993}
}
@inproceedings{ngomo2009borderflow,
  title={Borderflow: A local graph clustering algorithm for natural language processing},
  author={Ngomo, Axel-Cyrille Ngonga and Schumacher, Frank},
  booktitle={International Conference on Intelligent Text Processing and Computational Linguistics},
  pages={547--558},
  year={2009},
  XXXorganization={Springer}
}
@article{rosa2011topical,
  title={Topical clustering of tweets},
  author={Rosa, Kevin Dela and Shah, Rushin and Lin, Bo and Gershman, Anatole and Frederking, Robert},
  journal={ACM SIGIR: SWSM},
  volume={63},
  year={2011}
}
@article{li2008text,
  title={Text clustering with feature selection by using statistical data},
  author={Li, Yanjun and Luo, Congnan and Chung, Soon M},
  journal={IEEE Transactions on knowledge and Data Engineering},
  volume={20},
  number={5},
  pages={641--652},
  year={2008},
  XXXpublisher={IEEE}
}
@inproceedings{larsen1999fast,
  title={Fast and effective text mining using linear-time document clustering},
  author={Larsen, Bjornar and Aone, Chinatsu},
  booktitle={Proceedings of ACM SIGKDD},
  pages={16--22},
  year={1999},
  XXXorganization={Citeseer}
}
@article{zhong2005efficient,
  title={Efficient streaming text clustering},
  author={Zhong, Shi},
  journal={Neural Networks},
  volume={18},
  number={5-6},
  pages={790--798},
  year={2005},
  XXXpublisher={Elsevier}
}
@inproceedings{huang2008similarity,
  title={Similarity measures for text document clustering},
  author={Huang, Anna},
  booktitle={Proceedings of New Zealand computer science research student conference},
  volume={4},
  pages={9--56},
  year={2008}
}
@inproceedings{mehri2019pretraining,
  title={Pretraining Methods for Dialog Context Representation Learning},
  author={Mehri, Shikib and Razumovsakaia, Evgeniia and Zhao, Tiancheng and Eskenazi, Maxine},
  booktitle={Proceedings of ACL},
  year={2019}
}
@inproceedings{yang2014semi,
  title={Semi-supervised learning of dialogue acts using sentence similarity based on word embeddings},
  author={Yang, Xiaohao and Liu, Jia and Chen, Zhenfeng and Wu, Weilan},
  booktitle={Proceedings of ICALIP},
  doi={10.1109/ICALIP.2014.7009921},
  pages={882--886},
  year={2014},
  XXXorganization={IEEE}
}
@article{guz2009multi,
  title={Multi-view semi-supervised learning for dialog act segmentation of speech},
  author={Guz, Umit and Cuendet, S{\'e}bastien and Hakkani-Tur, Dilek and Tur, Gokhan},
  journal={IEEE TASLP},
  volume={18},
  number={2},
  pages={320--329},
  year={2009},
  XXXpublisher={IEEE}
}
@inproceedings{wen2017latent,
  title={Latent intention dialogue models},
  author={Wen, Tsung-Hsien and Miao, Yishu and Blunsom, Phil and Young, Steve},
  booktitle={Proceedings of ICML},
  pages={3732--3741},
  year={2017},
  XXXorganization={JMLR. org}
}
@inproceedings{yue2007support,
  title={A support vector method for optimizing average precision},
  author={Yue, Yisong and Finley, Thomas and Radlinski, Filip and Joachims, Thorsten},
  booktitle={Proceedings of ACM SIGIR},
  pages={271--278},
  year={2007},
  XXXorganization={ACM}
}

@article{young_pomdp-based_2013,
	title = {{POMDP}-Based Statistical Spoken Dialog Systems: A Review},
	volume = {101},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2012.2225812},
    number = {5},
	journal = {Proceedings of the IEEE},
	author = {Young, S. and Gasic, M. and Thomson, B. and Williams, J.D.},
	XXXmonth = may,
	year = {2013},
	pages = {1160--1179},
}


@inproceedings{zhao_zero-shot_2018,
	XXXaddress = {Melbourne, Australia},
	title = {Zero-Shot Dialog Generation with Cross-Domain Latent Actions},
	url = {http://aclweb.org/anthology/W18-5001},
	urldate = {2018-11-22},
	booktitle = {Proceedings of SIGDIAL},
	XXXpublisher = {Association for Computational Linguistics},
	author = {Zhao, Tiancheng and Eskenazi, Maxine},
	XXXmonth = jul,
	year = {2018},
	pages = {1--10},
}

@inproceedings{shalyminov_few-shot_2019,
	address = {Stockholm, Sweden},
	title = {Few-Shot Dialogue Generation Without Annotated Data: A Transfer Learning Approach},
	shorttitle = {Few-{Shot} {Dialogue} {Generation} {Without} {Annotated} {Data}},
	url = {http://arxiv.org/abs/1908.05854},
	booktitle = {Proceedings of SIGDIAL},
	author = {Shalyminov, Igor and Lee, Sungjin and Eshghi, Arash and Lemon, Oliver},
	XXXmonth = sep,
	year = {2019},
	XXXnote = {arXiv: 1908.05854},
}

@inproceedings{huang_mala_2020,
	address = {New York, NY, USA},
	title = {{MALA}: Cross-Domain Dialogue Generation with Action Learning},
	shorttitle = {{MALA}},
	url = {http://arxiv.org/abs/1912.08442},
	booktitle = {\ AAAI},
	author = {Huang, Xinting and Qi, Jianzhong and Sun, Yu and Zhang, Rui},
	XXXmonth = feb,
	year = {2020},
	XXXnote = {arXiv: 1912.08442},
}
@inproceedings{henderson2012discriminative,
  title={Discriminative spoken language understanding using word confusion networks},
  author={Henderson, Matthew and Ga{\v{s}}i{\'c}, Milica and Thomson, Blaise and Tsiakoulis, Pirros and Yu, Kai and Young, Steve},
  booktitle={Proceedings of IEEE SLT},
  pages={176--181},
  year={2012},
  doi={10.1109/SLT.2012.6424218},
  XXXorganization={IEEE}
}
@inproceedings{chen2010semafor,
  title={SEMAFOR: Frame argument resolution with log-linear models},
  author={Chen, Desai and Schneider, Nathan and Das, Dipanjan and Smith, Noah A},
  booktitle={5th international workshop on semantic evaluation},
  pages={264--267},
  year={2010},
  XXXorganization={Association for Computational Linguistics}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the ACL},
  volume={5},
  year={2017},
  pages={135--146},
  url={https://www.aclweb.org/anthology/Q17-1010/},
  XXXpublisher={MIT Press}
}
@inproceedings{Gardner2017AllenNLP,
  title={{AllenNLP}: A Deep Semantic Natural Language Processing Platform},
  author={Matt Gardner and Joel Grus and Mark Neumann and Oyvind Tafjord
    and Pradeep Dasigi and Nelson F. Liu and Matthew Peters and
    Michael Schmitz and Luke S. Zettlemoyer},
  year={2017},
  url={https://www.aclweb.org/anthology/W18-2501/},
  booktitle = {Proceedings of ACL Workshop for NLP Open Source Software (NLP-OSS)},
}
@inproceedings{eric2019multiwoz,
	address = {Marseille, France},
	title = {{MultiWOZ} 2.1: {A} {Consolidated} {Multi}-{Domain} {Dialogue} {Dataset} with {State} {Corrections} and {State} {Tracking} {Baselines}},
	url = {https://www.aclweb.org/anthology/2020.lrec-1.53},
	booktitle = {Proceedings of the 12th {Language} {Resources} and {Evaluation} {Conference}},
	author = {Eric, Mihail and Goel, Rahul and Paul, Shachi and Sethi, Abhishek and Agarwal, Sanchit and Gao, Shuyang and Kumar, Adarsh and Goyal, Anuj and Ku, Peter and Hakkani-Tur, Dilek},
	month = may,
	year = {2020},
	pages = {422--428},
}

@article{campos2020yake,
  title={YAKE! Keyword extraction from single documents using multiple local features},
  author={Campos, Ricardo and Mangaravite, V{\'\i}tor and Pasquali, Arian and Jorge, Al{\'\i}pio and Nunes, C{\'e}lia and Jatowt, Adam},
  journal={Information Sciences},
  year={2020},
  volume={509},
  pages={257--289},
  url={https://doi.org/10.1016/j.ins.2019.09.013},
  XXXpublisher={Elsevier}
}
@techreport{page1999pagerank,
  title={The {PageRank} citation ranking: Bringing order to the web.},
  author={Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry},
  year={1999},
  institution={Stanford InfoLab}
}

@inproceedings{hemphill_atis_1990,
	address = {Hidden Valley, Pennsylvania},
	title = {The {ATIS} spoken language systems pilot corpus},
	url = {https://www.aclweb.org/anthology/H90-1021/},
	doi = {10.3115/116580.116613},
	language = {en},
	urldate = {2018-08-30},
	booktitle = {Proceedings of the workshop on {Speech} and {Natural} {Language}  - {HLT} '90},
	author = {Hemphill, Charles T. and Godfrey, John J. and Doddington, George R.},
	year = {1990},
	pages = {96--101},
}

@inproceedings{li_diversity-promoting_2016,
	address = {San Diego, CA, USA},
	title = {A {Diversity}-{Promoting} {Objective} {Function} for {Neural} {Conversation} {Models}},
	url = {https://www.aclweb.org/anthology/N16-1014},
	booktitle = {Proceedings of the 15th {Annual} {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
	year = {2016},
	pages = {110--119},
}

@inproceedings{gao_2019_jointly,
	address = {Minneapolis, MN, USA},
	title = {Jointly {Optimizing} {Diversity} and {Relevance} in {Neural} {Response} {Generation}},
	booktitle = {Proceedings of NAACL},
	author = {Gao, Xiang and Lee, Sungjin and Zhang, Yizhe and Brockett, Chris and Galley, Michel and Gao, Jianfeng and Dolan, Bill},
	month = jun,
	year = {2019},
	url={https://www.aclweb.org/anthology/N19-1125/},
}
    
@inproceedings{cho2014learning,
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}-{Decoder} for {Statistical} {Machine} {Translation}},
	booktitle = {Proceedings of {EMNLP}},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = jun,
	year = {2014},
	pages = {1724--1734},
	url={https://www.aclweb.org/anthology/D14-1179/},
}

@article{serban_survey_2018,
	title = {A {Survey} of {Available} {Corpora} for {Building} {Data}-{Driven} {Dialogue} {Systems}: {The} {Journal} {Version}},
	volume = {9},
	doi = {10.5087/dad.2018.101},
    number = {1},
	journal = {Dialogue \& Discourse},
	author = {Serban, Iulian Vlad and Lowe, Ryan and Charlin, Laurent and Pineau, Joelle},
	month = may,
	year = {2018},
	pages = {1--49},
}

@inproceedings{goo_slot-gated_2018,
	address = {New Orleans, Louisiana},
	title = {Slot-{Gated} {Modeling} for {Joint} {Slot} {Filling} and {Intent} {Prediction}},
	url = {https://www.aclweb.org/anthology/N18-2118},
	doi = {10.18653/v1/N18-2118},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 2 ({Short} {Papers})},
	author = {Goo, Chih-Wen and Gao, Guang and Hsu, Yun-Kai and Huo, Chih-Li and Chen, Tsung-Chieh and Hsu, Keng-Wei and Chen, Yun-Nung},
	month = jun,
	year = {2018},
	pages = {753--757},
}


@inproceedings{coope_span-convert_2020,
	address = {Online},
	title = {Span-{ConveRT}: {Few}-shot {Span} {Extraction} for {Dialog} with {Pretrained} {Conversational} {Representations}},
	shorttitle = {Span-{ConveRT}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.11},
	urldate = {2020-07-15},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	author = {Coope, Samuel and Farghly, Tyler and Gerz, Daniela and Vulić, Ivan and Henderson, Matthew},
	month = jul,
	year = {2020},
	pages = {107--121},
}

@article{palmer2010semantic,
  title={Semantic role labeling},
  author={Palmer, Martha and Gildea, Daniel and Xue, Nianwen},
  journal={Synthesis Lectures on Human Language Technologies},
  volume={3},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{hulth2003improved,
  title={Improved automatic keyword extraction given more linguistic knowledge},
  url={https://www.aclweb.org/anthology/W03-1028/},
  author={Hulth, Anette},
  booktitle={Proceedings of EMNLP},
  pages={216--223},
  year={2003}
}

@inproceedings{bapna2017towards,
    title = {Towards {Zero}-{Shot} {Frame} {Semantic} {Parsing} for {Domain} {Scaling}},
    url = {http://www.isca-speech.org/archive/Interspeech_2017/abstracts/0518.html},
    doi = {10.21437/Interspeech.2017-518},
    booktitle = {Proceedings of Interspeech 2017},
    author = {Bapna, Ankur and Tür, Gokhan and Hakkani-Tür, Dilek and Heck, Larry},
    month = aug,
    year = {2017},
    pages = {2476--2480},
}

@inproceedings{shah2019robust,
    address = {Florence, Italy},
    title = {Robust {Zero}-{Shot} {Cross}-{Domain} {Slot} {Filling} with {Example} {Values}},
    url = {https://www.aclweb.org/anthology/P19-1547},
    doi = {10.18653/v1/P19-1547},
    booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
    author = {Shah, Darsh and Gupta, Raghav and Fayazi, Amir and Hakkani-Tur, Dilek},
    year = {2019},
    pages = {5484--5490},
}

@inproceedings{liu2020coach,
    address = {Online},
    title = {Coach: {A} {Coarse}-to-{Fine} {Approach} for {Cross}-domain {Slot} {Filling}},
    shorttitle = {Coach},
    url = {https://www.aclweb.org/anthology/2020.acl-main.3},
    booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
    author = {Liu, Zihan and Winata, Genta Indra and Xu, Peng and Fung, Pascale},
    month = jul,
    year = {2020},
    pages = {19--25},
}

@inproceedings{mrksic-etal-2017-neural,
    title = "Neural Belief Tracker: Data-Driven Dialogue State Tracking",
    author = "Mrk{\v{s}}i{\'c}, Nikola  and
      {\'O} S{\'e}aghdha, Diarmuid  and
      Wen, Tsung-Hsien  and
      Thomson, Blaise  and
      Young, Steve",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P17-1163",
    doi = "10.18653/v1/P17-1163",
    pages = "1777--1788",
    abstract = "One of the core components of modern spoken dialogue systems is the belief tracker, which estimates the user{'}s goal at every step of the dialogue. However, most current approaches have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted lexicons for capturing some of the linguistic variation in users{'} language. We propose a novel Neural Belief Tracking (NBT) framework which overcomes these problems by building on recent advances in representation learning. NBT models reason over pre-trained word vectors, learning to compose them into distributed representations of user utterances and dialogue context. Our evaluation on two datasets shows that this approach surpasses past limitations, matching the performance of state-of-the-art models which rely on hand-crafted semantic lexicons and outperforming them when such lexicons are not provided.",
}


@inproceedings{zhao-eskenazi-2016-towards,
    title = "Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning",
    author = "Zhao, Tiancheng  and
      Eskenazi, Maxine",
    booktitle = "Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2016",
    address = "Los Angeles",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W16-3601",
    doi = "10.18653/v1/W16-3601",
    pages = "1--10",
}
@inproceedings{core1997coding,
  title={Coding dialogs with the DAMSL annotation scheme},
  booktitle={.},
  author={Core, Mark G and Allen, James},
  year={1997}
}
@article{yaman2008integrative,
  title={An integrative and discriminative technique for spoken utterance classification},
  author={Yaman, Sibel and Deng, Li and Yu, Dong and Wang, Ye-Yi and Acero, Alex},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={16},
  number={6},
  pages={1207--1214},
  year={2008},
  publisher={IEEE}
}
@article{schapire2000boostexter,
  title={BoosTexter: A boosting-based system for text categorization},
  author={Schapire, Robert E and Singer, Yoram},
  journal={Machine learning},
  volume={39},
  number={2-3},
  pages={135--168},
  year={2000},
  publisher={Springer}
}
@inproceedings{surendran2006dialog,
  title={Dialog act tagging with support vector machines and hidden Markov models},
  author={Surendran, Dinoj and Levow, Gina-Anne},
  booktitle={Ninth International Conference on Spoken Language Processing},
  year={2006}
}
@inproceedings{shi2016recurrent,
  title={Recurrent support vector machines for slot tagging in spoken language understanding},
  author={Shi, Yangyang and Yao, Kaisheng and Chen, Hu and Yu, Dong and Pan, Yi-Cheng and Hwang, Mei-Yuh},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={393--399},
  year={2016}
}
@article{mesnil2014using,
  title={Using recurrent neural networks for slot filling in spoken language understanding},
  author={Mesnil, Gr{\'e}goire and Dauphin, Yann and Yao, Kaisheng and Bengio, Yoshua and Deng, Li and Hakkani-Tur, Dilek and He, Xiaodong and Heck, Larry and Tur, Gokhan and Yu, Dong and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={23},
  number={3},
  pages={530--539},
  year={2014},
  publisher={IEEE}
}
@inproceedings{zhang2017position,
  title={Position-aware attention and supervised data improve slot filling},
  author={Zhang, Yuhao and Zhong, Victor and Chen, Danqi and Angeli, Gabor and Manning, Christopher D},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={35--45},
  year={2017}
}
@article{adel2016comparing,
  title={Comparing convolutional neural networks to traditional models for slot filling},
  author={Adel, Heike and Roth, Benjamin and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:1603.05157},
  year={2016}
}
@inproceedings{zhang2016joint,
  title={A joint model of intent determination and slot filling for spoken language understanding.},
  author={Zhang, Xiaodong and Wang, Houfeng},
  booktitle={IJCAI},
  volume={16},
  pages={2993--2999},
  year={2016}
}
@article{liu2016attention,
  title={Attention-based recurrent neural network models for joint intent detection and slot filling},
  author={Liu, Bing and Lane, Ian},
  journal={arXiv preprint arXiv:1609.01454},
  year={2016}
}
@inproceedings{xu2013convolutional,
  title={Convolutional neural network based triangular crf for joint intent detection and slot filling},
  author={Xu, Puyang and Sarikaya, Ruhi},
  booktitle={2013 ieee workshop on automatic speech recognition and understanding},
  pages={78--83},
  year={2013},
  organization={IEEE}
}
@inproceedings{vzilka2013comparison,
  title={Comparison of bayesian discriminative and generative models for dialogue state tracking},
  author={{\v{Z}}ilka, Luk{\'a}{\v{s}} and Marek, David and Korvas, Mat{\v{e}}j and Jurcicek, Filip},
  booktitle={Proceedings of the SIGDIAL 2013 Conference},
  pages={452--456},
  year={2013}
}
@inproceedings{rastogi2017scalable,
  title={Scalable multi-domain dialogue state tracking},
  author={Rastogi, Abhinav and Hakkani-T{\"u}r, Dilek and Heck, Larry},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={561--568},
  year={2017},
  organization={IEEE}
}
@article{zhong2018global,
  title={Global-locally self-attentive dialogue state tracker},
  author={Zhong, Victor and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1805.09655},
  year={2018}
}

@article{gavsic2013gaussian,
  title={Gaussian processes for pomdp-based dialogue manager optimization},
  author={Ga{\v{s}}i{\'c}, Milica and Young, Steve},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={22},
  number={1},
  pages={28--40},
  year={2013},
  publisher={IEEE}
}
@inproceedings{lemon2007dialogue,
  title={Dialogue policy learning for combinations of noise and user simulation: transfer results},
  author={Lemon, Oliver and Liu, Xingkun},
  booktitle={Proc. SIGdial},
  year={2007}
}
@inproceedings{gavsic2010gaussian,
  title={Gaussian processes for fast policy optimisation of POMDP-based dialogue managers},
  author={Ga{\v{s}}i{\'c}, Milica and Jur{\v{c}}{\'\i}{\v{c}}ek, Filip and Keizer, Simon and Mairesse, Fran{\c{c}}ois and Thomson, Blaise and Yu, Kai and Young, Steve},
  booktitle={Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  pages={201--204},
  year={2010},
  organization={Association for Computational Linguistics}
}
@article{thomson2010bayesian,
  title={Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems},
  author={Thomson, Blaise and Young, Steve},
  journal={Computer Speech \& Language},
  volume={24},
  number={4},
  pages={562--588},
  year={2010},
  publisher={Elsevier}
}
@article{peng2017composite,
  title={Composite task-completion dialogue policy learning via hierarchical deep reinforcement learning},
  author={Peng, Baolin and Li, Xiujun and Li, Lihong and Gao, Jianfeng and Celikyilmaz, Asli and Lee, Sungjin and Wong, Kam-Fai},
  journal={arXiv preprint arXiv:1704.03084},
  year={2017}
}
@article{su2016line,
  title={On-line active reward learning for policy optimisation in spoken dialogue systems},
  author={Su, Pei-Hao and Gasic, Milica and Mrksic, Nikola and Rojas-Barahona, Lina and Ultes, Stefan and Vandyke, David and Wen, Tsung-Hsien and Young, Steve},
  journal={arXiv preprint arXiv:1605.07669},
  year={2016}
}
@inproceedings{serban2016building,
  title={Building end-to-end dialogue systems using generative hierarchical neural network models},
  author={Serban, Iulian V and Sordoni, Alessandro and Bengio, Yoshua and Courville, Aaron and Pineau, Joelle},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}
@article{williams2017hybrid,
  title={Hybrid code networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning},
  author={Williams, Jason D and Asadi, Kavosh and Zweig, Geoffrey},
  journal={arXiv preprint arXiv:1702.03274},
  year={2017}
}

@book{jurafsky2000speech,
  title={Speech \& language processing},
  author={Jurafsky, Dan},
  year={2000},
  publisher={Pearson Education India}
}
@inproceedings{tur2012exploiting,
  title={Exploiting the semantic web for unsupervised natural language semantic parsing},
  author={Tur, Gokhan and Jeong, Minwoo and Wang, Ye-Yi and Hakkani-T{\"u}r, Dilek and Heck, Larry},
  booktitle={13th Annual Conference of the International Speech Communication Association},
  year={2012}
}

@article{berners2001semantic,
  title={The semantic web},
  author={Berners-Lee, Tim and Hendler, James and Lassila, Ora and others},
  journal={Scientific American},
  volume={284},
  number={5},
  pages={28--37},
  year={2001},
  XXXpublisher={New York, NY, USA:}
}
@inproceedings{hakkani2013using,
  title={Using a knowledge graph and query click logs for unsupervised learning of relation detection},
  author={Hakkani-T{\"u}r, Dilek and Heck, Larry and Tur, Gokhan},
  booktitle={Proc.\ IEEE ICASSP},
  pages={8327--8331},
  year={2013},
  XXXorganization={IEEE}
}
@inproceedings{wang2014leveraging,
  title={Leveraging semantic web search and browse sessions for multi-turn spoken dialog systems},
  author={Wang, Lu and Heck, Larry and Hakkani-T{\"u}r, Dilek},
  booktitle={Proc.\ IEEE ICASSP},
  pages={4082--4086},
  year={2014},
  XXXorganization={IEEE}
}

@inproceedings{shi2018auto,
  title={Auto-{Dialabel}: Labeling Dialogue Data with Unsupervised Learning},
  author={Shi, Chen and Chen, Qi and Sha, Lei and Li, Sujian and Sun, Xu and Wang, Houfeng and Zhang, Lintao},
  booktitle={Proc.\ EMNLP},
  pages={684--689},
  year={2018}
}
@article{fillmore1976frame,
  title={Frame semantics and the nature of language},
  author={Fillmore, Charles J},
  journal={Ann.\ N.\ Y.\ Acad.\ Sci},
  year={1976},
  XXXpublisher={Wiley Online Library}
}

@inproceedings{chen2015jointly,
  title={Jointly modeling inter-slot relations by random walk on knowledge graphs for unsupervised spoken language understanding},
  author={Chen, Yun-Nung and Wang, William Yang and Rudnicky, Alexander},
  booktitle={Proc.\ NAACL},
  pages={619--629},
  year={2015}
}
@inproceedings{chen2016zero,
  title={Zero-shot learning of intent embeddings for expansion by convolutional deep structured semantic models},
  author={Chen, Yun-Nung and Hakkani-T{\"u}r, Dilek and He, Xiaodong},
  booktitle={Proc.\ IEEE ICASSP},
  pages={6045--6049},
  year={2016},
  XXXorganization={IEEE}
}
@article{mehri2019pretraining,
  title={Pretraining Methods for Dialog Context Representation Learning},
  author={Mehri, Shikib and Razumovsakaia, Evgeniia and Zhao, Tiancheng and Eskenazi, Maxine},
  journal={arXiv preprint arXiv:1906.00414},
  year={2019}
}
@inproceedings{yang2014semi,
  title={Semi-supervised learning of dialogue acts using sentence similarity based on word embeddings},
  author={Yang, Xiaohao and Liu, Jia and Chen, Zhenfeng and Wu, Weilan},
  booktitle={2014 International Conference on Audio, Language and Image Processing},
  pages={882--886},
  year={2014},
  organization={IEEE}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@article{zhao2017infovae,
  title={Infovae: Information maximizing variational autoencoders},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  journal={arXiv preprint arXiv:1706.02262},
  year={2017}
}

@article{bowman2015generating,
  title={Generating sentences from a continuous space},
  author={Bowman, Samuel R and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M and Jozefowicz, Rafal and Bengio, Samy},
  journal={arXiv preprint arXiv:1511.06349},
  year={2015}
}
@inproceedings{van2017neural,
  title={Neural discrete representation learning},
  author={van den Oord, Aaron and Vinyals, Oriol and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6306--6315},
  year={2017}
}
@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}
@inproceedings{chung2015recurrent,
  title={A recurrent latent variable model for sequential data},
  author={Chung, Junyoung and Kastner, Kyle and Dinh, Laurent and Goel, Kratarth and Courville, Aaron C and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2980--2988},
  year={2015}
}
@inproceedings{oh2000stochastic,
  title={Stochastic language generation for spoken dialogue systems},
  author={Oh, Alice and Rudnicky, Alexander},
  booktitle={ANLP-NAACL 2000 Workshop: Conversational Systems},
  year={2000}
}

@article{huang2019mala,
  title={MALA: Cross-Domain Dialogue Generation with Action Learning},
  author={Huang, Xinting and Qi, Jianzhong and Sun, Yu and Zhang, Rui},
  journal={arXiv preprint arXiv:1912.08442},
  year={2019}
}
@article{brychcin2016unsupervised,
  title={Unsupervised dialogue act induction using gaussian mixtures},
  author={Brychc{\'\i}n, Tom{\'a}{\v{s}} and Kr{\'a}l, Pavel},
  journal={arXiv preprint arXiv:1612.06572},
  year={2016}
}
@article{shi2019unsupervised,
  title={Unsupervised Dialog Structure Learning},
  author={Shi, Weiyan and Zhao, Tiancheng and Yu, Zhou},
  journal={arXiv preprint arXiv:1904.03736},
  year={2019}
}
@inproceedings{mihalcea2004textrank,
  title={Textrank: Bringing order into text},
  author={Mihalcea, Rada and Tarau, Paul},
  booktitle={Proc.\ EMNLP},
  XXXpages={404--411},
  year={2004}
}
@inproceedings{lample2016neural,
  title={Neural architectures for named entity recognition},
  author={Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
  booktitle={Proc.\ NAACL},
  year={2016}
}

@article{gu2016incorporating,
  title={Incorporating copying mechanism in sequence-to-sequence learning},
  author={Gu, Jiatao and Lu, Zhengdong and Li, Hang and Li, Victor OK},
  journal={arXiv preprint arXiv:1603.06393},
  year={2016}
}

@inproceedings{lowe2017towards,
  title={Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses},
  author={Lowe, Ryan and Noseworthy, Michael and Serban, Iulian Vlad and Angelard-Gontier, Nicolas and Bengio, Yoshua and Pineau, Joelle},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1116--1126},
  year={2017}
}
@misc{sarikaya2018dialogue,
  title={Dialogue evaluation via multiple hypothesis ranking},
  author={Sarikaya, Ruhi and Boies, Daniel and Crook, Paul A and Robichaud, Jean-Philippe},
  year={2018},
  month=dec # "~25",
  publisher={Google Patents},
  note={US Patent 10,162,813}
}

@article{werbos1990backpropagation,
  title={Backpropagation through time: what it does and how to do it},
  author={Werbos, Paul J},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1550--1560},
  year={1990},
  publisher={IEEE}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@inproceedings{dahl1994expanding,
  title={Expanding the scope of the ATIS task: The ATIS-3 corpus},
  author={Dahl, Deborah A and Bates, Madeleine and Brown, Michael K and Fisher, William M and Hunicke-Smith, Kate and Pallett, David S and Pao, Christine and Rudnicky, Alexander and Shriberg, Elizabeth},
  booktitle={Human Language Technology: Proceedings of a Workshop held at Plainsboro, New Jersey, March 8-11, 1994},
  year={1994}
}

@article{qiu2022structure,
  title={Structure extraction in task-oriented dialogues with slot clustering},
  author={Qiu, Liang and Wu, Chien-Sheng and Liu, Wenhao and Xiong, Caiming},
  journal={arXiv preprint arXiv:2203.00073},
  year={2022}
}

@article{deriu_survey_2021,
	title = {Survey on {Evaluation} {Methods} for {Dialogue} {Systems}},
	volume = {54},
	url = {http://arxiv.org/abs/1905.04071},
	doi = {10.1007/s10462-020-09866-x},
	abstract = {In this paper we survey the methods and concepts developed for the evaluation of dialogue systems. Evaluation is a crucial part during the development process. Often, dialogue systems are evaluated by means of human evaluations and questionnaires. However, this tends to be very cost and time intensive. Thus, much work has been put into finding methods, which allow to reduce the involvement of human labour. In this survey, we present the main concepts and methods. For this, we differentiate between the various classes of dialogue systems (task-oriented dialogue systems, conversational dialogue systems, and question-answering dialogue systems). We cover each class by introducing the main technologies developed for the dialogue systems and then by presenting the evaluation methods regarding this class.},
	urldate = {2019-10-11},
	journal = {Artificial Intelligence Review},
	author = {Deriu, Jan and Rodrigo, Alvaro and Otegi, Arantxa and Echegoyen, Guillermo and Rosset, Sophie and Agirre, Eneko and Cieliebak, Mark},
	month = jan,
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	pages = {755--810},
	file = {arXiv\:1905.04071 PDF:C\:\\Users\\Ondra\\Zotero\\storage\\QLQ4IXKG\\Deriu et al. - 2019 - Survey on Evaluation Methods for Dialogue Systems.pdf:application/pdf},
}


@inproceedings{rudnicky_creating_1999,
	title = {Creating natural dialogs in the {Carnegie} {Mellon} {Communicator} system},
	url = {http://www.speech.cs.cmu.edu/Communicator/papers/Natural\%20Dialogs2.pdf},
	urldate = {2015-10-26},
	booktitle = {Proceedings of the 6th {European} {Conference} on {Speech} {Communication} and {Technology}},
	author = {Rudnicky, Alexander I. and Thayer, Eric H. and Constantinides, Paul C. and Tchou, Chris and Shern, R. and Lenzo, Kevin A. and Xu, Wei and Oh, Alice},
	year = {1999},
	keywords = {Let's Go, Rosetta},
	pages = {1531--1534},
	file = {[PDF] z cmu.edu:C\:\\Users\\Ondra\\Zotero\\storage\\U2Q588QK\\Rudnicky et al. - 1999 - Creating natural dialogs in the carnegie mellon co.pdf:application/pdf}
}

@article{DBLP:journals/corr/abs-1901-08149,
  author    = {Thomas Wolf and
               Victor Sanh and
               Julien Chaumond and
               Clement Delangue},
  title     = {TransferTransfo: {A} Transfer Learning Approach for Neural Network
               Based Conversational Agents},
  journal   = {CoRR},
  volume    = {abs/1901.08149},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.08149},
  archivePrefix = {arXiv},
  eprint    = {1901.08149},
  timestamp = {Sat, 02 Feb 2019 16:56:00 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-08149.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{chao2019bert,
  title={BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer},
  journal={arXiv preprint arXiv:1910.07931},
  author={Chao, Guan-Lin and Lane, Ian},
  year={2019}
}
@article{bao2019plato,
  title={PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable},
  author={Bao, Siqi and He, Huang and Wang, Fan and Wu, Hua},
  journal={arXiv preprint arXiv:1910.07931},
  year={2019}
}
@article{shalyminov2020hybrid,
  title={Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation},
  author={Shalyminov, Igor and Sordoni, Alessandro and Atkinson, Adam and Schulz, Hannes},
  journal={arXiv preprint arXiv:2003.01680},
  year={2020}
}


@inproceedings{keizer-etal-2019-user,
    title = "User Evaluation of a Multi-dimensional Statistical Dialogue System",
    author = "Keizer, Simon  and
      Du{\v{s}}ek, Ond{\v{r}}ej  and
      Liu, Xingkun  and
      Rieser, Verena",
    booktitle = "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue",
    month = sep,
    year = "2019",
    address = "Stockholm, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5945",
    doi = "10.18653/v1/W19-5945",
    pages = "392--398",
    abstract = "We present the first complete spoken dialogue system driven by a multiimensional statistical dialogue manager. This framework has been shown to substantially reduce data needs by leveraging domain-independent dimensions, such as social obligations or feedback, which (as we show) can be transferred between domains. In this paper, we conduct a user study and show that the performance of a multi-dimensional system, which can be adapted from a source domain, is equivalent to that of a one-dimensional baseline, which can only be trained from scratch.",
}

@inproceedings{kingma2013auto,
 	address = {Banff, AB, Canada},
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	booktitle = {International {Conference} on {Learning} {Representations} ({ICLR})},
	author = {Kingma, Diederik P. and Welling, Max},
	month = apr,
	year = {2014},
}

@inproceedings{peng2020few,
	title = {Few-shot {Natural} {Language} {Generation} for {Task}-{Oriented} {Dialog}},
	url = {https://www.aclweb.org/anthology/2020.findings-emnlp.17},
	booktitle = {Findings of EMNLP},
	author = {Peng, Baolin and Zhu, Chenguang and Li, Chunyuan and Li, Xiujun and Li, Jinchao and Zeng, Michael and Gao, Jianfeng},
	month = nov,
	year = {2020},
	pages = {172--182},
}

@article{zhang2020probabilistic,
  title={A probabilistic end-to-end task-oriented dialog model with latent belief states towards semi-supervised learning},
  author={Zhang, Yichi and Ou, Zhijian and Wang, Huixin and Feng, Junlan},
  journal={arXiv preprint arXiv:2009.08115},
  year={2020}
}

@inproceedings{jang2017categorical,
  title={Categorical Reparameterization with Gumbel-Softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={International Conference on Learning Representations (ICLR 2017)},
  year={2017},
  url={https://arxiv.org/abs/1611.01144},
}

@inproceedings{bowman-etal-2016-generating,
    title = "Generating Sentences from a Continuous Space",
    author = "Bowman, Samuel R.  and
      Vilnis, Luke  and
      Vinyals, Oriol  and
      Dai, Andrew  and
      Jozefowicz, Rafal  and
      Bengio, Samy",
    booktitle = "Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K16-1002",
    doi = "10.18653/v1/K16-1002",
    pages = "10--21",
}

@inproceedings{kingma2017,
  author    = {Xi Chen and
               Diederik P. Kingma and
               Tim Salimans and
               Yan Duan and
               Prafulla Dhariwal and
               John Schulman and
               Ilya Sutskever and
               Pieter Abbeel},
  title     = {Variational Lossy Autoencoder},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=BysvGP5ee},
  timestamp = {Thu, 25 Jul 2019 14:25:55 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/0022KSDDSSA17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Zhao_Song_Ermon_2019, 
    title={{InfoVAE}: Balancing Learning and Inference in Variational Autoencoders}, 
    XXXvolume={33}, 
    url={https://ojs.aaai.org/index.php/AAAI/article/view/4538}, DOI={10.1609/aaai.v33i01.33015885},
    XXXnumber={01}, 
    booktitle={Proceedings of the 33rd AAAI Conference on Artificial Intelligence}, 
    author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano}, 
    year={2019}, 
    month={Jul.}, 
    pages={5885-5892} 
}

@inproceedings{vandenoord2017,
author = {van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
title = {Neural Discrete Representation Learning},
url={https://arxiv.org/abs/1711.00937},
year = {2017},
isbn = {9781510860964},
XXXpublisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6309–6318},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{serban2016hierarchical,
	address = {San Francisco, CA, USA},
	title = {A {Hierarchical} {Latent} {Variable} {Encoder}-{Decoder} {Model} for {Generating} {Dialogues}},
	url = {http://arxiv.org/abs/1605.06069},
	booktitle = {Proceedings of the 31th {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Serban, Iulian Vlad and Sordoni, Alessandro and Lowe, Ryan and Charlin, Laurent and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
	month = feb,
	year = {2017},
    pages = {3295–3301},
}


@inproceedings{serban2015building,
	address = {Phoenix, AZ, USA},
	title = {Building {End}-{To}-{End} {Dialogue} {Systems} {Using} {Generative} {Hierarchical} {Neural} {Network} {Models}},
	url = {http://arxiv.org/abs/1507.04808},
	booktitle = {Proceedings of the 30th {AAAI} {Conference} on {Artificial} {Intelligence}},
	author = {Serban, Iulian V. and Sordoni, Alessandro and Bengio, Yoshua and Courville, Aaron and Pineau, Joelle},
	year = {2016},
}

@inproceedings{zhao2018unsupervised,
	address = {Melbourne, Australia},
	title = {Unsupervised {Discrete} {Sentence} {Representation} {Learning} for {Interpretable} {Neural} {Dialog} {Generation}},
	url = {http://aclweb.org/anthology/P18-1101},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	author = {Zhao, Tiancheng and Lee, Kyusong and Eskenazi, Maxine},
	month = jul,
	year = {2018},
	pages = {1098--1107},
}


@misc{fabius2015variational,
      title={Variational Recurrent Auto-Encoders}, 
      author={Otto Fabius and Joost R. van Amersfoort},
      year={2015},
      eprint={1412.6581},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{gunasekara2018quantized,
  title={Quantized-dialog language model for goal-oriented conversational systems},
  author={Gunasekara, R Chulaka and Nahamoo, David and Polymenakos, Lazaros C and Ganhotra, Jatin and Fadnis, Kshitij P},
  booktitle={DSTC6 -- Dialog System Technology Challenges},
  address={Long Beach, CA, USA},
  url={https://arxiv.org/abs/1812.10356},
  note={arXiv:1812.10356},
  year={2017},
}


@article{hochreiter1997,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}

@inproceedings{papineni2002,
    title = "{BLEU}: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    XXXpublisher = "Association for Computational Linguistics",
    url ="https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}


@inproceedings{zhai-williams-2014-discovering,
    title = "Discovering Latent Structure in Task-Oriented Dialogues",
    author = "Zhai, Ke  and
      Williams, Jason D.",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    XXXpublisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P14-1004",
    doi = "10.3115/v1/P14-1004",
    pages = "36--46",
}

@inproceedings{anirudh2017,
author = {Goyal, Anirudh and Sordoni, Alessandro and C\^{o}t\'{e}, Marc-Alexandre and Ke, Nan Rosemary and Bengio, Yoshua},
title = {Z-Forcing: Training Stochastic Recurrent Networks},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6716–6726},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@inproceedings{zhang_probabilistic_2020,
	address = {Online},
	title = {A {Probabilistic} {End}-{To}-{End} {Task}-{Oriented} {Dialog} {Model} with {Latent} {Belief} {States} towards {Semi}-{Supervised} {Learning}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.740},
    booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Zhang, Yichi and Ou, Zhijian and Hu, Min and Feng, Junlan},
	month = nov,
	year = {2020},
    pages = {9207--9219},
}

@inproceedings{qin2020dynamic,
 address = {Online},
 author = {Libo Qin and
Xiao Xu and
Wanxiang Che and
Yue Zhang and
Ting Liu},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/acl/QinXCZL20.bib},
 booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, {ACL} 2020},
 doi = {10.18653/v1/2020.acl-main.565},
 editor = {Dan Jurafsky and
Joyce Chai and
Natalie Schluter and
Joel R. Tetreault},
 pages = {6344--6354},
 timestamp = {Thu, 14 Oct 2021 01:00:00 +0200},
 title = {{Dynamic} {Fusion} {Network} for {Multi-Domain} {End-to-end} {Task-Oriented} {Dialog}},
 url = {https://doi.org/10.18653/v1/2020.acl-main.565},
 year = {2020}
}

@inproceedings{lin2020mintl,
 address = {Online},
 author = {Zhaojiang Lin and
Andrea Madotto and
Genta Indra Winata and
Pascale Fung},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/emnlp/LinMWF20.bib},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2020},
 doi = {10.18653/v1/2020.emnlp-main.273},
 editor = {Bonnie Webber and
Trevor Cohn and
Yulan He and
Yang Liu},
 pages = {3391--3405},
 timestamp = {Wed, 23 Mar 2022 10:11:55 +0100},
 title = {{MinTL:} {Minimalist} {Transfer} {Learning} for {Task-Oriented} {Dialogue} {Systems}},
 url = {https://doi.org/10.18653/v1/2020.emnlp-main.273},
 year = {2020}
}

@article{peng2021soloist,
 author = {Baolin Peng and
Chunyuan Li and
Jinchao Li and
Shahin Shayandeh and
Lars Liden and
Jianfeng Gao},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/tacl/PengLLSLG21.bib},
 doi = {10.1162/tacl\_a\_00399},
 journal = {Trans. Assoc. Comput. Linguistics},
 pages = {907--824},
 timestamp = {Fri, 10 Jun 2022 01:00:00 +0200},
 title = {{SOLOIST:} {Building} {Task} {Bots} at {Scale} with {Transfer} {Learning} and {Machine} {Teaching}},
 url = {https://doi.org/10.1162/tacl\_a\_00399},
 volume = {9},
 year = {2021}
}

@inproceedings{wen2017,
    title = "A Network-based End-to-End Trainable Task-oriented Dialogue System",
    author = "Wen, Tsung-Hsien  and Vandyke, David  and Mrk{\v{s}}i{\'c}, Nikola and Ga{\v{s}}i{\'c}, Milica and Rojas-Barahona, Lina M. and u, Pei-Hao and Ultes, Stefan  and Young, Steve",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics (EACL)",
    year = "2017",
    address = "Valencia, Spain",
    XXXpublisher = "Association for Computational Linguistics",
    XXXurl ="https://www.aclweb.org/anthology/E17-1042",
    pages = "438--449"
}

@inproceedings{lei2018,
    title = "{S}equicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures",
    author = "Lei, Wenqiang and Jin, Xisen  and Kan, Min-Yen  and Ren, Zhaochun  and He, Xiangnan  and Yin, Dawei",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2018",
    address = "Melbourne, Australia",
    XXXpublisher = "Association for Computational Linguistics",
    url ="https://www.aclweb.org/anthology/P18-1133",
    doi = "10.18653/v1/P18-1133",
    pages = "1437--1447",
}

@inproceedings{pu2016,
author = {Pu, Yunchen and Gan, Zhe and Henao, Ricardo and Yuan, Xin and Li, Chunyuan and Stevens, Andrew and Carin, Lawrence},
title = {Variational Autoencoder for Deep Learning of Images, Labels and Captions},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {2360–2368},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}


@inproceedings{wen_semantically_2015,
	address = {Lisbon, Portugal},
	title = {Semantically {Conditioned} {LSTM}-based {Natural} {Language} {Generation} for {Spoken} {Dialogue} {Systems}},
	url = {http://aclweb.org/anthology/D15-1199},
	urldate = {2015-10-01},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Wen, Tsung-Hsien and Gasic, Milica and Mrkšić, Nikola and Su, Pei-Hao and Vandyke, David and Young, Steve},
	month = sep,
	year = {2015},
	pages = {1711--1721},
}

@inproceedings{henderson-etal-2014-word,
    title = "Word-Based Dialog State Tracking with Recurrent Neural Networks",
    author = "Henderson, Matthew  and
      Thomson, Blaise  and
      Young, Steve",
    booktitle = "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL})",
    month = jun,
    year = "2014",
    address = "Philadelphia, PA, U.S.A.",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W14-4340",
    doi = "10.3115/v1/W14-4340",
    pages = "292--299",
}

@inproceedings{gu_incorporating_2016,
	address = {Berlin, Germany},
	title = {Incorporating {Copying} {Mechanism} in {Sequence}-to-{Sequence} {Learning}},
	url = {https://www.aclweb.org/anthology/P16-1154/},
    booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	author = {Gu, Jiatao and Lu, Zhengdong and Li, Hang and Li, Victor O. K.},
	month = aug,
	year = {2016},
	pages = {1631--1640},

}

@inproceedings{bordes2016learning,
 address = {Toulon, France},
 author = {Antoine Bordes and
Y{-}Lan Boureau and
Jason Weston},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/BordesBW17.bib},
 booktitle = {5th International Conference on Learning Representations, {ICLR} 2017},
 timestamp = {Tue, 23 Jul 2019 01:00:00 +0200},
 title = {{Learning} {End-to-End} {Goal-Oriented} {Dialog}},
 url = {https://openreview.net/forum?id=S1Bb3D5gg},
 year = {2017}
}


@inproceedings{ham_end--end_2020,
	address = {Online},
	title = {End-to-{End} {Neural} {Pipeline} for {Goal}-{Oriented} {Dialogue} {Systems} using {GPT}-2},
	url = {https://www.aclweb.org/anthology/2020.acl-main.54},
	abstract = {The goal-oriented dialogue system needs to be optimized for tracking the dialogue flow and carrying out an effective conversation under various situations to meet the user goal. The traditional approach to build such a dialogue system is to take a pipelined modular architecture, where its modules are optimized individually. However, such an optimization scheme does not necessarily yield the overall performance improvement of the whole system. On the other hand, end-to-end dialogue systems with monolithic neural architecture are often trained only with input-output utterances, without taking into account the entire annotations available in the corpus. This scheme makes it difficult for goal-oriented dialogues where the system needs to integrate with external systems or to provide interpretable information about why the system generated a particular response. In this paper, we present an end-to-end neural architecture for dialogue systems that addresses both challenges above. In the human evaluation, our dialogue system achieved the success rate of 68.32\%, the language understanding score of 4.149, and the response appropriateness score of 4.287, which ranked the system at the top position in the end-to-end multi-domain dialogue system task in the 8th dialogue systems technology challenge (DSTC8).},
	urldate = {2020-07-10},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Ham, Donghoon and Lee, Jeong-Gwan and Jang, Youngsoo and Kim, Kee-Eung},
	month = jul,
	year = {2020},
	keywords = {inspiring},
	pages = {583--592},
	file = {Full Text PDF:C\:\\Users\\Ondra\\Zotero\\storage\\6I5SXVI9\\Ham et al. - 2020 - End-to-End Neural Pipeline for Goal-Oriented Dialo.pdf:application/pdf}
}


@inproceedings{zhang2019,
  title={Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context},
  author={Zhang, Yichi and Ou, Zhijian and Yu, Zhou},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  address={New York, NY, USA},
  pages={9604-9611},
  year={2020}
}

@article{hosseini2020,
  title={A simple language model for task-oriented dialogue},
  author={Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
  journal={arXiv preprint arXiv:2005.00796},
  year={2020}
}

@techreport{radford2019,
	title = {Language {Models} are {Unsupervised} {Multitask} {Learners}},
	institution = {OpenAI},
	author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	year = {2019},
 url = {https://openai.com/blog/better-language-models/},
}

@inproceedings{wen2017,
    title = "A Network-based End-to-End Trainable Task-oriented Dialogue System",
    author = "Wen, Tsung-Hsien  and Vandyke, David  and Mrk{\v{s}}i{\'c}, Nikola and Ga{\v{s}}i{\'c}, Milica and Rojas-Barahona, Lina M. and u, Pei-Hao and Ultes, Stefan  and Young, Steve",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics (EACL)",
    year = "2017",
    address = "Valencia, Spain",
    XXXpublisher = "Association for Computational Linguistics",
    url ="https://www.aclweb.org/anthology/E17-1042",
    pages = "438--449"
}


@inproceedings{devlin2019,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and Chang, Ming-Wei  and Lee, Kenton  and Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)",
    year = "2019",
    address = "Minneapolis, MN, USA",
    XXXpublisher = "Association for Computational Linguistics",
    url ="https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186"
}

@inproceedings{wu2018,
    title={Global-to-local Memory Pointer Networks for Task-Oriented Dialogue},
    author={Chien-Sheng Wu and Richard Socher and Caiming Xiong},
    booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
    year={2019},
    address = {New Orleans, LA, USA},
    url={https://openreview.net/forum?id=ryxnHhRqFm},
}

@inproceedings{shu2019,
    title = "Flexibly-Structured Model for Task-Oriented Dialogues",
    author = "Shu, Lei  and Molino, Piero  and Namazifar, Mahdi  and Xu, Hu  and Liu, Bing  and Zheng, Huaixiu  and Tur, Gokhan",
    booktitle = "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue",
    year = "2019",
    address = "Stockholm, Sweden",
    XXXpublisher = "Association for Computational Linguistics",
    url ="https://www.aclweb.org/anthology/W19-5922",
    doi = "10.18653/v1/W19-5922",
    pages = "178--187"
}

@article{liu2020,
    title={Ro{BERT}a: A Robustly Optimized {BERT} Pretraining Approach},
    author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
    journal = {arXiv preprint arXiv:1907.11692},
    year={2019},
}

@inproceedings{wu2020-todbert,
  title={{ToD-BERT}: Pre-trained Natural Language Understanding for Task-Oriented Dialogues},
  author={Wu, Chien-Sheng and Hoi, Steven and Socher, Richard and Xiong, Caiming},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2020},
  url={https://aclanthology.org/2020.emnlp-main.66/},
  address={Online},
  pages={917–929},
}

@inproceedings{zhang2020dialogpt,
    title = "{DIALOGPT} : Large-Scale Generative Pre-training for Conversational Response Generation",
    author = "Zhang, Yizhe and Sun, Siqi  and Galley, Michel  and Chen, Yen-Chun and Brockett, Chris and Gao, Xiang  and Gao, Jianfeng  and Liu, Jingjing  and Dolan, Bill",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations",
    year = "2020",
    address={Online},
    XXXpublisher = "Association for Computational Linguistics",
    url ="https://www.aclweb.org/anthology/2020.acl-demos.30",
    doi = "10.18653/v1/2020.acl-demos.30",
    pages = "270--278",
}

@inproceedings{nekvinda2021shades,
    title = "Shades of {BLEU}, Flavours of Success: The Case of {M}ulti{WOZ}",
    author = "Nekvinda, Tom{\'a}{\v{s}}  and
      Du{\v{s}}ek, Ond{\v{r}}ej",
    booktitle = "Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.gem-1.4",
    doi = "10.18653/v1/2021.gem-1.4",
    pages = "34--46",
}

@article{zhang2019dialogpt,
  title={Dialogpt: Large-scale generative pre-training for conversational response generation},
  author={Zhang, Yizhe and Sun, Siqi and Galley, Michel and Chen, Yen-Chun and Brockett, Chris and Gao, Xiang and Gao, Jianfeng and Liu, Jingjing and Dolan, Bill},
  journal={arXiv preprint arXiv:1911.00536},
  year={2019}
}

@article{raghu2021unsupervised,
 author = {Dinesh Raghu and
Nikhil Gupta and
Mausam},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/tacl/RaghuGM21.bib},
 doi = {10.1162/tacl\_a\_00372},
 journal = {Trans. Assoc. Comput. Linguistics},
 pages = {374--390},
 timestamp = {Fri, 10 Jun 2022 01:00:00 +0200},
 title = {{Unsupervised} {Learning} of {KB} {Queries} in {Task-Oriented} {Dialogs}},
 url = {https://doi.org/10.1162/tacl\_a\_00372},
 volume = {9},
 year = {2021}
}

@article{vaeTrans,
  author    = {Zhaojiang Lin and
               Genta Indra Winata and
               Peng Xu and
               Zihan Liu and
               Pascale Fung},
  title     = {Variational Transformers for Diverse Response Generation},
  journal   = {CoRR},
  volume    = {abs/2003.12738},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.12738},
  eprinttype = {arXiv},
  eprint    = {2003.12738},
  timestamp = {Fri, 27 Nov 2020 10:48:03 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-12738.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{huang-etal-2020-generalizable,
    title = "Generalizable and Explainable Dialogue Generation via Explicit Action Learning",
    author = "Huang, Xinting  and
      Qi, Jianzhong  and
      Sun, Yu  and
      Zhang, Rui",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.355",
    doi = "10.18653/v1/2020.findings-emnlp.355",
    pages = "3981--3991",
    abstract = "Response generation for task-oriented dialogues implicitly optimizes two objectives at the same time: task completion and language quality. Conditioned response generation serves as an effective approach to separately and better optimize these two objectives. Such an approach relies on system action annotations which are expensive to obtain. To alleviate the need of action annotations, latent action learning is introduced to map each utterance to a latent representation. However, this approach is prone to over-dependence on the training data, and the generalization capability is thus restricted. To address this issue, we propose to learn \textit{natural language actions} that represent utterances as a span of words. This explicit action representation promotes generalization via the compositional structure of language. It also enables an explainable generation process. Our proposed unsupervised approach learns a memory component to summarize system utterances into a short span of words. To further promote a compact action representation, we propose an auxiliary task that restores state annotations as the summarized dialogue context using the memory component. Our proposed approach outperforms latent action baselines on MultiWOZ, a benchmark multi-domain dataset.",
}

@inproceedings{zhao-etal-2019-rethinking,
    title = "Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog Agents with Latent Variable Models",
    author = "Zhao, Tiancheng  and
      Xie, Kaige  and
      Eskenazi, Maxine",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1123",
    doi = "10.18653/v1/N19-1123",
    pages = "1208--1218",
    abstract = "Defining action spaces for conversational agents and optimizing their decision-making process with reinforcement learning is an enduring challenge. Common practice has been to use handcrafted dialog acts, or the output vocabulary, e.g. in neural encoder decoders, as the action spaces. Both have their own limitations. This paper proposes a novel latent action framework that treats the action spaces of an end-to-end dialog agent as latent variables and develops unsupervised methods in order to induce its own action space from the data. Comprehensive experiments are conducted examining both continuous and discrete action types and two different optimization methods based on stochastic variational inference. Results show that the proposed latent actions achieve superior empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for policy learning and can serve as a foundation for developing better latent actions in future research.",
}


@inproceedings{stevens-su-2021-investigation,
    title = "An Investigation of Language Model Interpretability via Sentence Editing",
    author = "Stevens, Samuel  and
      Su, Yu",
    booktitle = "Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.blackboxnlp-1.34",
    doi = "10.18653/v1/2021.blackboxnlp-1.34",
    pages = "435--446",
    abstract = "Pre-trained language models (PLMs) like BERT are being used for almost all language-related tasks, but interpreting their behavior still remains a significant challenge and many important questions remain largely unanswered. In this work, we re-purpose a sentence editing dataset, where faithful high-quality human rationales can be automatically extracted and compared with extracted model rationales, as a new testbed for interpretability. This enables us to conduct a systematic investigation on an array of questions regarding PLMs{'} interpretability, including the role of pre-training procedure, comparison of rationale extraction methods, and different layers in the PLM. The investigation generates new insights, for example, contrary to the common understanding, we find that attention weights correlate well with human rationales and work better than gradient-based saliency in extracting model rationales. Both the dataset and code will be released to facilitate future interpretability research.",
}

@inproceedings{lin-etal-2019-open,
    title = "Open Sesame: Getting inside {BERT}{'}s Linguistic Knowledge",
    author = "Lin, Yongjie  and
      Tan, Yi Chern  and
      Frank, Robert",
    booktitle = "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-4825",
    doi = "10.18653/v1/W19-4825",
    pages = "241--253",
    abstract = "How and to what extent does BERT encode syntactically-sensitive hierarchical information or positionally-sensitive linear information? Recent work has shown that contextual representations like BERT perform well on tasks that require sensitivity to linguistic structure. We present here two studies which aim to provide a better understanding of the nature of BERT{'}s representations. The first of these focuses on the identification of structurally-defined elements using diagnostic classifiers, while the second explores BERT{'}s representation of subject-verb agreement and anaphor-antecedent dependencies through a quantitative assessment of self-attention vectors. In both cases, we find that BERT encodes positional information about word tokens well on its lower layers, but switches to a hierarchically-oriented encoding on higher layers. We conclude then that BERT{'}s representations do indeed model linguistically relevant aspects of hierarchical structure, though they do not appear to show the sharp sensitivity to hierarchical structure that is found in human processing of reflexive anaphora.",
}

@inproceedings{bao-etal-2020-plato,
    title = "{PLATO}: Pre-trained Dialogue Generation Model with Discrete Latent Variable",
    author = "Bao, Siqi  and
      He, Huang  and
      Wang, Fan  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.9",
    doi = "10.18653/v1/2020.acl-main.9",
    pages = "85--96",
    abstract = "Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.",
}

@inproceedings{liu-etal-2021-dialoguecse,
    title = "{D}ialogue{CSE}: Dialogue-based Contrastive Learning of Sentence Embeddings",
    author = "Liu, Che  and
      Wang, Rui  and
      Liu, Jinghua  and
      Sun, Jian  and
      Huang, Fei  and
      Si, Luo",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.185",
    doi = "10.18653/v1/2021.emnlp-main.185",
    pages = "2396--2406",
    abstract = "Learning sentence embeddings from dialogues has drawn increasing attention due to its low annotation cost and high domain adaptability. Conventional approaches employ the siamese-network for this task, which obtains the sentence embeddings through modeling the context-response semantic relevance by applying a feed-forward network on top of the sentence encoders. However, as the semantic textual similarity is commonly measured through the element-wise distance metrics (e.g. cosine and L2 distance), such architecture yields a large gap between training and evaluating. In this paper, we propose DialogueCSE, a dialogue-based contrastive learning approach to tackle this issue. DialogueCSE first introduces a novel matching-guided embedding (MGE) mechanism, which generates a context-aware embedding for each candidate response embedding (i.e. the context-free embedding) according to the guidance of the multi-turn context-response matching matrices. Then it pairs each context-aware embedding with its corresponding context-free embedding and finally minimizes the contrastive loss across all pairs. We evaluate our model on three multi-turn dialogue datasets: the Microsoft Dialogue Corpus, the Jing Dong Dialogue Corpus, and the E-commerce Dialogue Corpus. Evaluation results show that our approach significantly outperforms the baselines across all three datasets in terms of MAP and Spearman{'}s correlation measures, demonstrating its effectiveness. Further quantitative experiments show that our approach achieves better performance when leveraging more dialogue context and remains robust when less training data is provided.",
}

@inproceedings{sun2021unsupervised,
  title={Unsupervised learning of deterministic dialogue structure with edge-enhanced graph auto-encoder},
  author={Sun, Yajing and Shan, Yong and Tang, Chengguang and Hu, Yue and Dai, Yinpei and Yu, Jing and Sun, Jian and Huang, Fei and Si, Luo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13869--13877},
  year={2021},
  address = {Virtual Event},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/17634},
}
@inproceedings{reimers-2019-sentence-bert,
  title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2019",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/1908.10084",
}


@inproceedings{henderson_robust_2014,
	title = {Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation},
	doi = {10.1109/SLT.2014.7078601},
	booktitle = {2014 {IEEE} {Spoken} {Language} {Technology} {Workshop} ({SLT})},
	author = {Henderson, Matthew and Thomson, Blaise and Young, Steve},
	month = dec,
	year = {2014},
	pages = {360--365},
}


% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}


@inproceedings{rastogi2020towards,
  title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},
  author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  number={05},
  pages={8689--8696},
  year={2020}
}


@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@inproceedings{yang2021ubar,
  title={Ubar: Towards fully end-to-end task-oriented dialog system with gpt-2},
  author={Yang, Yunyi and Li, Yunhao and Quan, Xiaojun},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={14230-14238},
  year={2021}
}


@inproceedings{shalyminov_fast_2020,
	title = {Fast {Domain} {Adaptation} for {Goal}-{Oriented} {Dialogue} {Using} a {Hybrid} {Generative}-{Retrieval} {Transformer}},
	doi = {10.1109/ICASSP40776.2020.9053599},
	abstract = {Goal-oriented dialogue systems are now widely adopted in industry, where practical aspects of using them becomes of key importance. As such, it is expected from such systems to fit into a rapid prototyping cycle for new products and domains. For data-driven dialogue systems (especially those based on deep learning) that amounts to maintaining production-level performance having been provided with a few `seed' dialogue examples, normally referred to as data efficiency.With extremely data-dependent deep learning methods, the most promising way to achieve practical data efficiency is transfer learning-i.e., leveraging a greater, highly represented data source for training a base model, then fine-tuning it to available in-domain data.In this paper, we present a hybrid generative-retrieval model that can be trained using transfer learning. By using GPT-2 as the base model and fine-tuning it to the multidomain MetaLWOz dataset, we obtain a robust dialogue model able to perform both response generation and ranking 1. Combining both, it outperforms several competitive generative-only and retrieval-only baselines, measured by language modeling quality on MetaLWOz as well as in goal- oriented metrics (Intent/Slot Fl-scores) on the MultiWoz corpus.},
	booktitle = {{ICASSP} 2020 - 2020 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Shalyminov, I. and Sordoni, A. and Atkinson, A. and Schulz, H.},
	month = may,
	year = {2020},
	note = {ISSN: 2379-190X},
	keywords = {domain adaptation, interactive systems, learning (artificial intelligence), neural nets, Dialogue systems, deep learning, information retrieval, data efficiency, data source, data-driven dialogue systems, generative-retrieval model, goal-oriented dialogue systems, goal-oriented metrics, hybrid generative-retrieval transformer, in-domain data, rapid prototyping cycle, response generation, retrieval-only baselines, robust dialogue model, transfer learning},
	pages = {8039--8043},
	file = {Shalyminov et al. - 2020 - Fast Domain Adaptation for Goal-Oriented Dialogue .pdf:C\:\\Users\\Ondra\\Zotero\\storage\\I9DJJGZP\\Shalyminov et al. - 2020 - Fast Domain Adaptation for Goal-Oriented Dialogue .pdf:application/pdf},
}

@inproceedings{hu-etal-2022-context,
    title = "In-Context Learning for Few-Shot Dialogue State Tracking",
    author = "Hu, Yushi  and
      Lee, Chia-Hsuan  and
      Xie, Tianbao  and
      Yu, Tao  and
      Smith, Noah A.  and
      Ostendorf, Mari",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.193",
    pages = "2627--2643",
    abstract = "Collecting and annotating task-oriented dialogues is time-consuming and costly. Thus, zero and few shot learning for dialogue tasks presents an exciting opportunity. In this work, we propose an in-context (IC) learning framework for zero-shot and few-shot learning dialogue state tracking (DST), where a large pretrained language model (LM) takes a test instance and a few exemplars as input, and directly decodes the dialogue state without any parameter updates. This approach is more flexible and scalable than prior DST work when adapting to new domains and scenarios. To better leverage a tabular domain description in the LM prompt, we reformulate DST into a text-to-SQL problem. We also propose a novel approach to retrieve annotated dialogues as exemplars. Empirical results on MultiWOZ show that our method IC-DST substantially outperforms previous fine-tuned state-of-the-art models in few-shot settings. In addition, we test IC-DST in zero-shot settings, in which the model only takes a fixed task instruction as input, finding that it outperforms previous zero-shot methods by a large margin.",
}



@inproceedings{DBLP:journals/corr/WestonCB14,
  author       = {Jason Weston and
                  Sumit Chopra and
                  Antoine Bordes},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Memory Networks},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1410.3916},
  timestamp    = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/WestonCB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{neil2016phased,
	isbn = {978-1-5108-3881-9},
	year = {2017},
	booktitle = {Advances in Neural Information Processing Systems 29},
	type = {Conference Paper},
	editor = {Lee, Daniel D. and von Luxburg, Ulrike and Garnett, Roman and Sugiyama, Masashi and Guyon, Isabelle},
	author = {Neil, Daniel and Pfeiffer, Michael and Liu, Shih-Chii},
	language = {en},
	address = {Red Hook, NY},
	publisher = {Curran},
	title = {Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences},
	PAGES = {3889 - 3898},
	Note = {30th Annual Conference on Neural Information Processing Systems (NIPS 2016); Conference Location: Barcelona, Spain; Conference Date: December 5-10, 2016; Poster presentation}
}

@article{sukhbaatar2015end,
  title={End-to-end memory networks},
  author={Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{lu-etal-2022-unsupervised,
    title = "Unsupervised Learning of Hierarchical Conversation Structure",
    author = "Lu, Bo-Ru  and
      Hu, Yushi  and
      Cheng, Hao  and
      Smith, Noah A.  and
      Ostendorf, Mari",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.415",
    pages = "5657--5670",
    abstract = "Human conversations can evolve in many different ways, creating challenges for automatic understanding and summarization. Goal-oriented conversations often have meaningful sub-dialogue structure, but it can be highly domain-dependent. This work introduces an unsupervised approach to learning hierarchical conversation structure, including turn and sub-dialogue segment labels, corresponding roughly to dialogue acts and sub-tasks, respectively. The decoded structure is shown to be useful in enhancing neural models of language for three conversation-level understanding tasks. Further, the learned finite-state sub-dialogue network is made interpretable through automatic summarization.",
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}

@inproceedings{supernaturalinstructions,
  title={Super-NaturalInstructions:Generalization via Declarative Instructions on 1600+ Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  booktitle={EMNLP},
  year={2022}
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{black2022gpt,
  title={Gpt-neox-20b: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={arXiv preprint arXiv:2204.06745},
  year={2022}
}

@article{iyer2022opt,
  title={OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization},
  author={Iyer, Srinivasan and Lin, Xi Victoria and Pasunuru, Ramakanth and Mihaylov, Todor and Simig, D{\'a}niel and Yu, Ping and Shuster, Kurt and Wang, Tianlu and Liu, Qing and Koura, Punit Singh and others},
  journal={arXiv preprint arXiv:2212.12017},
  year={2022}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@inproceedings{rastogi2020towards,
  title={Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset},
  author={Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  number={05},
  pages={8689--8696},
  year={2020}
}

@inproceedings{reimers-2020-multilingual-sentence-bert,
  title = "Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation",
  author = "Reimers, Nils and Gurevych, Iryna",
  booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
  month = "11",
  year = "2020",
  publisher = "Association for Computational Linguistics",
  url = "https://arxiv.org/abs/2004.09813",
}

@article{johnson2019billion,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{lei2018sequicity,
  title={Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures},
  author={Lei, Wenqiang and Jin, Xisen and Kan, Min-Yen and Ren, Zhaochun and He, Xiangnan and Yin, Dawei},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1437--1447},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}


@article{madotto2020language,
  title={Language models as few-shot learner for task-oriented dialogue systems},
  author={Madotto, Andrea and Liu, Zihan and Lin, Zhaojiang and Fung, Pascale},
  journal={arXiv preprint arXiv:2008.06239},
  year={2020}
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth international conference on the principles of knowledge representation and reasoning},
  year={2012}
}


@inproceedings{huang2020mala,
  author    = {Xinting Huang and
               Jianzhong Qi and
               Yu Sun and
               Rui Zhang},
  title     = {{MALA:} Cross-Domain Dialogue Generation with Action Learning},
  booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
               2020, The Thirty-Second Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
               February 7-12, 2020},
  pages     = {7977--7984},
  publisher = {{AAAI} Press},
  year      = {2020},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/6306},
  timestamp = {Mon, 07 Mar 2022 16:58:05 +0100},
  biburl    = {https://dblp.org/rec/conf/aaai/Huang00020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{budzianowski_multiwoz_2018,
	address = {Brussels, Belgium},
	title = {{MultiWOZ} - {A} {Large}-{Scale} {Multi}-{Domain} {Wizard}-of-{Oz} {Dataset} for {Task}-{Oriented} {Dialogue} {Modelling}},
	url = {https://aclanthology.org/D18-1547/},
	abstract = {Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available. To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of \$10\$k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora. The contribution of this work apart from the open-sourced dataset labelled with dialogue belief states and dialogue actions is two-fold: firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators; secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.},
	urldate = {2018-10-08},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Budzianowski, Paweł and Wen, Tsung-Hsien and Tseng, Bo-Hsiang and Casanueva, Iñigo and Ultes, Stefan and Ramadan, Osman and Gašić, Milica},
	month = nov,
	year = {2018},
	note = {arXiv: 1810.00278},
	keywords = {Computer Science - Computation and Language, MultiWOZ},
	pages = {5016--5026},
	annote = {Comment: Accepted for publication at EMNLP 2018},
	file = {arXiv\:1810.00278 PDF:C\:\\Users\\Ondra\\Zotero\\storage\\VSYEHCJ7\\Budzianowski et al. - 2018 - MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz.pdf:application/pdf},
}


@misc{zhao_survey_2023,
	title = {A {Survey} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2303.18223},
	doi = {10.48550/arXiv.2303.18223},
	abstract = {Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.},
	urldate = {2023-04-08},
	publisher = {arXiv},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	month = mar,
	year = {2023},
	note = {arXiv:2303.18223 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: ongoing work; 51 pages},
	file = {arXiv Fulltext PDF:C\:\\Users\\Ondra\\Zotero\\storage\\3GR7AQAV\\Zhao et al. - 2023 - A Survey of Large Language Models.pdf:application/pdf},
}

@article{su2022selective,
  title={Selective annotation makes language models better few-shot learners},
  author={Su, Hongjin and Kasai, Jungo and Wu, Chen Henry and Shi, Weijia and Wang, Tianlu and Xin, Jiayi and Zhang, Rui and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A and others},
  journal={arXiv preprint arXiv:2209.01975},
  year={2022}
}

@article{huangrobustness,
  title={Robustness through Data Augmentation Loss Consistency},
  author={Huang, Tianjian and Halbe, Shaunak Ashish and Sankar, Chinnadhurai and Amini, Pooyan and Kottur, Satwik and Geramifard, Alborz and Razaviyayn, Meisam and Beirami, Ahmad},
  journal={Transactions on Machine Learning Research},
  year={2023},
  url = {https://openreview.net/forum?id=a1meaRy1bN}
}

@article{sun2022mars,
  title={Mars: Semantic-aware Contrastive Learning for End-to-End Task-Oriented Dialog},
  author={Sun, Haipeng and Bao, Junwei and Wu, Youzheng and He, Xiaodong},
  journal={arXiv preprint arXiv:2210.08917},
  year={2022}
}

@article{feng2023fantastic,
  title={Fantastic Rewards and How to Tame Them: A Case Study on Reward Learning for Task-oriented Dialogue Systems},
  author={Feng, Yihao and Yang, Shentao and Zhang, Shujian and Zhang, Jianguo and Xiong, Caiming and Zhou, Mingyuan and Wang, Huan},
  journal={arXiv preprint arXiv:2302.10342},
  year={2023}
}


@article{zhu2022convlab3,
    title={ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data Format},
    author={Qi Zhu and Christian Geishauser and Hsien-chin Lin and Carel van Niekerk and Baolin Peng and Zheng Zhang and Michael Heck and Nurul Lubis and Dazhen Wan and Xiaochen Zhu and Jianfeng Gao and Milica Gašić and Minlie Huang},
    journal={arXiv preprint arXiv:2211.17148},
    year={2022},
    url={http://arxiv.org/abs/2211.17148}
}


@inproceedings{rastogi_multi-task_2018,
	address = {Melbourne, Australia},
	title = {Multi-task {Learning} for {Joint} {Language} {Understanding} and {Dialogue} {State} {Tracking}},
	url = {https://aclanthology.org/W18-5045},
	doi = {10.18653/v1/W18-5045},
	abstract = {This paper presents a novel approach for multi-task learning of language understanding (LU) and dialogue state tracking (DST) in task-oriented dialogue systems. Multi-task training enables the sharing of the neural network layers responsible for encoding the user utterance for both LU and DST and improves performance while reducing the number of network parameters. In our proposed framework, DST operates on a set of candidate values for each slot that has been mentioned so far. These candidate sets are generated using LU slot annotations for the current user utterance, dialogue acts corresponding to the preceding system utterance and the dialogue state estimated for the previous turn, enabling DST to handle slots with a large or unbounded set of possible values and deal with slot values not seen during training. Furthermore, to bridge the gap between training and inference, we investigate the use of scheduled sampling on LU output for the current user utterance as well as the DST output for the preceding turn.},
	urldate = {2023-05-21},
	booktitle = {Proceedings of the 19th {Annual} {SIGdial} {Meeting} on {Discourse} and {Dialogue}},
	publisher = {Association for Computational Linguistics},
	author = {Rastogi, Abhinav and Gupta, Raghav and Hakkani-Tur, Dilek},
	month = jul,
	year = {2018},
	pages = {376--384},
	file = {Full Text PDF:C\:\\Users\\Ondra\\Zotero\\storage\\UELG7YGW\\Rastogi et al. - 2018 - Multi-task Learning for Joint Language Understandi.pdf:application/pdf},
}


@inproceedings{lewis_bart:_2020,
	address = {Online},
	title = {{BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}},
	shorttitle = {{BART}},
	url = {https://aclanthology.org/2020.acl-main.703/},
	doi = {10.18653/v1/2020.acl-main.703},
	abstract = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance.},
	urldate = {2021-02-15},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
	month = jul,
	year = {2020},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning, Xinnuo, Xsum/BBC data, Zdenek},
	pages = {7871--7880},
	file = {Full Text PDF:C\:\\Users\\Ondra\\Zotero\\storage\\U5C67R54\\Lewis et al. - 2020 - BART Denoising Sequence-to-Sequence Pre-training .pdf:application/pdf},
}

@inproceedings{DBLP:conf/aaai/LiangTCY20,
  author       = {Weixin Liang and
                  Youzhi Tian and
                  Chengcai Chen and
                  Zhou Yu},
  title        = {{MOSS:} End-to-End Dialog System Framework with Modular Supervision},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {8327--8335},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/6349},
  timestamp    = {Thu, 13 Jul 2023 13:56:51 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/LiangTCY20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{vahdat2020nvae,
  title={NVAE: A deep hierarchical variational autoencoder},
  author={Vahdat, Arash and Kautz, Jan},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19667--19679},
  year={2020}
}

@article{li2020progressive,
  title={Progressive learning and disentanglement of hierarchical representations},
  author={Li, Zhiyuan and Murkute, Jaideep Vitthal and Gyawali, Prashnna Kumar and Wang, Linwei},
  journal={arXiv preprint arXiv:2002.10549},
  year={2020}
}
@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@Book{GoodBengCour16,
  Title                    = {Deep Learning},
  Author                   = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  Publisher                = {MIT Press},
  Year                     = {2016},

  Address                  = {Cambridge, MA, USA},
  Note                     = {\url{http://www.deeplearningbook.org}}
}

@inproceedings{mosbach-etal-2023-shot,
    title = "Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation",
    author = "Mosbach, Marius  and
      Pimentel, Tiago  and
      Ravfogel, Shauli  and
      Klakow, Dietrich  and
      Elazar, Yanai",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.779",
    doi = "10.18653/v1/2023.findings-acl.779",
    pages = "12284--12314",
    abstract = "Few-shot fine-tuning and in-context learning are two alternative strategies for task adaptation of pre-trained language models. Recently, in-context learning has gained popularity over fine-tuning due to its simplicity and improved out-of-domain generalization, and because extensive evidence shows that fine-tuned models pick up on spurious correlations. Unfortunately, previous comparisons of the two approaches were done using models of different sizes. This raises the question of whether the observed weaker out-of-domain generalization of fine-tuned models is an inherent property of fine-tuning or a limitation of the experimental setup. In this paper, we compare the generalization of few-shot fine-tuning and in-context learning to challenge datasets, while controlling for the models used, the number of examples, and the number of parameters, ranging from 125M to 30B. Our results show that fine-tuned language models can in fact generalize well out-of-domain. We find that both approaches generalize similarly; they exhibit large variation and depend on properties such as model size and the number of examples, highlighting that robust task adaptation remains a challenge.",
}

@article{DBLP:journals/pieee/YoungGTW13,
  author       = {Steve J. Young and
                  Milica Gasic and
                  Blaise Thomson and
                  Jason D. Williams},
  title        = {POMDP-Based Statistical Spoken Dialog Systems: {A} Review},
  journal      = {Proc. {IEEE}},
  volume       = {101},
  number       = {5},
  pages        = {1160--1179},
  year         = {2013},
  url          = {https://doi.org/10.1109/JPROC.2012.2225812},
  doi          = {10.1109/JPROC.2012.2225812},
  timestamp    = {Sun, 02 Oct 2022 15:46:02 +0200},
  biburl       = {https://dblp.org/rec/journals/pieee/YoungGTW13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchaboutnfdi

@article{Weisser2016,
author = {Martin Weisser},
doi = {doi:10.1515/cllt-2014-0051},
url = {https://doi.org/10.1515/cllt-2014-0051},
title = {DART – The dialogue annotation and research tool},
journal = {Corpus Linguistics and Linguistic Theory},
number = {2},
volume = {12},
year = {2016},
pages = {355--388}
}

@inproceedings{wen-etal-2017-wizard-of-oz,
    title = "A Network-based End-to-End Trainable Task-oriented Dialogue System",
    author = "Wen, Tsung-Hsien  and
      Vandyke, David  and
      Mrk{\v{s}}i{\'c}, Nikola  and
      Ga{\v{s}}i{\'c}, Milica  and
      Rojas-Barahona, Lina M.  and
      Su, Pei-Hao  and
      Ultes, Stefan  and
      Young, Steve",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E17-1042",
    pages = "438--449",
    abstract = "Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.",
}

@book{manning99foundations,
  added-at = {2007-12-07T10:02:43.000+0100},
  address = {Cambridge, Massachusetts},
  author = {Manning, Christopher D. and Sch{\"u}tze, Hinrich},
  biburl = {https://www.bibsonomy.org/bibtex/22fad675aa6ae88082af2507c16d54343/hotho},
  interhash = {a81df02f92f266a51183fe936f588a08},
  intrahash = {2fad675aa6ae88082af2507c16d54343},
  keywords = {lecture nlp},
  publisher = {The {MIT} Press},
  timestamp = {2007-12-07T10:02:43.000+0100},
  title = {Foundations of Statistical Natural Language Processing},
  url = {http://nlp.stanford.edu/fsnlp/},
  year = 1999
}

@article{kelley1960gradient,
  title={Gradient theory of optimal flight paths},
  author={Kelley, Henry J},
  journal={Ars Journal},
  volume={30},
  number={10},
  pages={947--954},
  year={1960}
}

@inproceedings{goutte2005probabilistic,
  title={A probabilistic interpretation of precision, recall and F-score, with implication for evaluation},
  author={Goutte, Cyril and Gaussier, Eric},
  booktitle={European conference on information retrieval},
  pages={345--359},
  year={2005},
  organization={Springer}
}

@article{hu2022context,
  title={In-context learning for few-shot dialogue state tracking},
  author={Hu, Yushi and Lee, Chia-Hsuan and Xie, Tianbao and Yu, Tao and Smith, Noah A and Ostendorf, Mari},
  journal={arXiv preprint arXiv:2203.08568},
  year={2022}
}

@article{zhang2023sgp,
  title={SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting},
  author={Zhang, Xiaoying and Peng, Baolin and Li, Kun and Zhou, Jingyan and Meng, Helen},
  journal={arXiv preprint arXiv:2305.09067},
  year={2023}
}

@article{xie2022converse,
  title={Converse: A Tree-Based Modular Task-Oriented Dialogue System},
  author={Xie, Tian and Yang, Xinyi and Lin, Angela S and Wu, Feihong and Hashimoto, Kazuma and Qu, Jin and Kang, Young Mo and Yin, Wenpeng and Wang, Huan and Yavuz, Semih and others},
  journal={arXiv preprint arXiv:2203.12187},
  year={2022}
}
