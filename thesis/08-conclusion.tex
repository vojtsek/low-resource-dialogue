%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}
\label{chap:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this work, we discuss the problems of data annotation needed for task-oriented dialogue modeling.
We propose multiple approaches to tackle this issue.
In the following, we summarize our findings and formulate some of the conclusions we draw from the experiments.
Finally, we also discuss possible future research directions in this field.

\section{Unsupervised techniques for automatic data annotation}
Automatic data labeling procedures are desirable since they can save expensive resources by providing valuable insights into the gathered conversation data.
In Chapter~\ref{chap:data_analysis}, we propose a pipeline method for the unsupervised discovery of dialogue slot schema and automatic labeling.
The pipeline is generic because it can take an arbitrary set of input candidates, regardless of the candidate identification method.
We show that the method can successfully exploit the inputs and refine the initial candidate pool.
Moreover, we have shown that the outputs of our pipeline can be used as a noisy supervision for training task-oriented dialogue system models.

\section{Less supervision for end-to-end TOD models}
The ultimate goal is to be able to train task-oriented dialogue models solely from an unlabeled input corpus.
As an intermediate step toward this goal, we introduce a novel usage of latent variable models for TOD generation in Chapter~\ref{chap:modeling}.
In particular, we focus on latent system action modeling and providing the model with a means to communicate with external interfaces using only sparse annotations.
Modeling task-oriented dialogue this way is challenging, and achieving competitive performance with SoTA supervised models is hard.
However, our latent action models based on variational training show some promising properties and have the potential for interoperability.

Another direction is to use full supervision but minimize the amount of required training data.
We explore this path in Chapters~\ref{chap:lm-tod}~and~\ref{chap:llms}.
The power of pre-trained language models is great, and they can achieve good performance with only a fraction of the training set available to them.
Although they seem to struggle with the belief state tracking task, this can likely be fixed with fine-tuning techniques, and, according to our findings, the usage of large language models promises to bridge the gap between academic datasets and real-world use cases as they can handle various conversation behaviors very well. 

\section{Future research directions}
